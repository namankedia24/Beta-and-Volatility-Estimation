{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.api import OLS\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "all_data = pd.read_csv('MSF_1996_2023.csv', low_memory=False)\n",
    "\n",
    "# Convert date to datetime\n",
    "all_data['date'] = pd.to_datetime(all_data['date'])\n",
    "\n",
    "# Sort the dataframe by date and PERMNO\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data.sort_values(['date', 'PERMNO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_industry(siccd):\n",
    "    if 1 <= siccd <= 999:\n",
    "        return \"Agriculture, Forestry and Fishing\"\n",
    "    elif 1000 <= siccd <= 1499:\n",
    "        return \"Mining\"\n",
    "    elif 1500 <= siccd <= 1799:\n",
    "        return \"Construction\"\n",
    "    elif 2000 <= siccd <= 3999:\n",
    "        return \"Manufacturing\"\n",
    "    elif 4000 <= siccd <= 4999:\n",
    "        return \"Transportation and other Utilities\"\n",
    "    elif 5000 <= siccd <= 5199:\n",
    "        return \"Wholesale Trade\"\n",
    "    elif 5200 <= siccd <= 5999:\n",
    "        return \"Retail Trade\"\n",
    "    elif 6000 <= siccd <= 6799:\n",
    "        return \"Finance, Insurance and Real Estate\"\n",
    "    elif 7000 <= siccd <= 8999:\n",
    "        return \"Services\"\n",
    "    else:\n",
    "        return \"Public Administration\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_labels = [\n",
    "    \"Agriculture, Forestry and Fishing\",\n",
    "    \"Mining\",\n",
    "    \"Construction\",\n",
    "    \"Manufacturing\",\n",
    "    \"Transportation and other Utilities\",\n",
    "    \"Wholesale Trade\",\n",
    "    \"Retail Trade\",\n",
    "    \"Finance, Insurance and Real Estate\",\n",
    "    \"Services\",\n",
    "    \"Public Administration\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['SICCDINT'] = pd.to_numeric(all_data['SICCD'], errors='coerce')\n",
    "all_data = all_data.dropna(subset=['SICCDINT'])\n",
    "all_data['industry'] = all_data['SICCDINT'].apply(map_industry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_unique_companies(group):\n",
    "    unique_companies = group.drop_duplicates(subset='PERMNO')\n",
    "    if len(unique_companies) > 10:\n",
    "        return unique_companies.sample(10)\n",
    "    else:\n",
    "        return unique_companies\n",
    "\n",
    "def select_sample(df, year):\n",
    "    year_data = df[df['date'].dt.year == year]\n",
    "    return year_data.groupby('industry').apply(sample_unique_companies).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['RET'] = pd.to_numeric(all_data['RET'], errors='coerce')\n",
    "all_data['vwretd'] = pd.to_numeric(all_data['vwretd'], errors='coerce')\n",
    "all_data = all_data.dropna(subset=['RET', 'vwretd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [select_sample(all_data, year) for year in range(1996, 2024)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = all_data.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_beta(returns, market_returns):\n",
    "    X = sm.add_constant(market_returns)\n",
    "    model = OLS(returns, X).fit()\n",
    "    beta = model.params[1]  # Beta is the coefficient of market_returns\n",
    "    alpha = model.params[0]  # Alpha is the intercept\n",
    "    residuals = model.resid\n",
    "    residual_var = residuals.var()\n",
    "    var_market_returns = market_returns.var()\n",
    "    var_returns = returns.var()\n",
    "    \n",
    "    return beta, alpha, residual_var, var_market_returns, var_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_df = pd.DataFrame(columns=['PERMCO', 'Year', 'Window', 'Beta', 'Alpha', 'Residual Var', 'Market Var', 'Stock Var', 'Industry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_betas_for_sample(full_data, sample_firms, beta_df1, year, window):\n",
    "    sample_permnos = sample_firms['PERMNO'].unique()\n",
    "    full_data = full_data.sort_values(['PERMNO', 'date'])\n",
    "    data_for_beta = full_data[full_data['PERMNO'].isin(sample_permnos)]\n",
    "    for firm in sample_permnos:\n",
    "        firm_data = data_for_beta[(data_for_beta['PERMNO'] == firm) & (data_for_beta['date'].dt.year <= year) & (data_for_beta['date'].dt.year > (year - (window)/12))]\n",
    "        if(firm_data['RET'].shape[0] < 10):\n",
    "            continue\n",
    "        beta, alpha, residual_var, var_market_returns, var_returns = estimate_beta(firm_data['RET'], firm_data['vwretd'])\n",
    "        industry_value = firm_data['industry'].iloc[0] \n",
    "\n",
    "        new_row = {\n",
    "            'PERMCO': firm,\n",
    "            'Year': year,\n",
    "            'Window': window,\n",
    "            'Beta': beta,\n",
    "            'Alpha': alpha,\n",
    "            'Residual Var': residual_var,\n",
    "            'Market Var': var_market_returns,\n",
    "            'Stock Var': var_returns,\n",
    "            'Industry': industry_value\n",
    "        }\n",
    "\n",
    "        beta_df1 = beta_df1.append(new_row, ignore_index=True)\n",
    "    return beta_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate betas for each sample\n",
    "year = 1996\n",
    "beta_df = pd.DataFrame(columns=['PERMCO', 'Year', 'Window', 'Beta', 'Alpha', 'Residual Var', 'Market Var', 'Stock Var', 'Industry'])\n",
    "for sample in samples:\n",
    "    beta_df = calculate_betas_for_sample(final_df, sample, beta_df, year , 12)\n",
    "    beta_df = calculate_betas_for_sample(final_df, sample, beta_df, year , 24)\n",
    "    beta_df = calculate_betas_for_sample(final_df, sample, beta_df, year , 36)\n",
    "    year = year + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_permnos = samples[0]['PERMNO'].unique()\n",
    "# final_df = final_df.sort_values(['PERMNO', 'date'])\n",
    "# data_for_beta = final_df[final_df['PERMNO'].isin(sample_permnos)]\n",
    "# data_for_beta['PERMNO'].unique()\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "def descriptive_stats(group):\n",
    "    return pd.Series({\n",
    "        'N': group.count(),\n",
    "        'mean': group.mean(),\n",
    "        'std_dev': group.std(),\n",
    "        'min': group.min(),\n",
    "        'max': group.max(),\n",
    "        '1%': group.quantile(0.01),\n",
    "        '5%': group.quantile(0.05),\n",
    "        '25%': group.quantile(0.25),\n",
    "        '50%': group.median(),\n",
    "        '75%': group.quantile(0.75),\n",
    "        '95%': group.quantile(0.95),\n",
    "        '99%': group.quantile(0.99),\n",
    "        'skewness': skew(group, bias=False),\n",
    "        'kurtosis': kurtosis(group, bias=False)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by industry and apply the descriptive_stats function to 'Beta' column\n",
    "result = beta_df.groupby('Industry')['Beta'].apply(descriptive_stats).unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_wise_result = beta_df.groupby(['Industry', 'Year'])['Beta'].apply(descriptive_stats).unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "    Descriptive Stats Industry Wise\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "# Convert the DataFrame to an HTML table with scrollable output\n",
    "display(HTML(result.to_html(max_rows=500, max_cols=20)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "    Descriptive Stats Industry-Year Wise\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML(year_wise_result.to_html(max_rows=500, max_cols=20)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "    Mean Betas Graph across industries\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Group by 'industry' and 'year', then compute mean and standard deviation\n",
    "agg_stats = beta_df.groupby(['Industry', 'Year'])['Beta'].agg(['mean', 'std']).reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "agg_stats.columns = ['Industry', 'Year', 'mean_beta', 'std_beta']\n",
    "\n",
    "# Set up the plotting area\n",
    "plt.figure(figsize=(24, 8))\n",
    "\n",
    "# Get unique industries\n",
    "industries = agg_stats['Industry'].unique()\n",
    "\n",
    "# Plot each industry's mean and standard deviation over time\n",
    "for industry in industries:\n",
    "    industry_data = agg_stats[agg_stats['Industry'] == industry]\n",
    "    \n",
    "    plt.plot(industry_data['Year'], industry_data['mean_beta'], label=f'{industry} Mean', linestyle='-', marker='o')\n",
    "#     plt.fill_between(industry_data['Year'],\n",
    "#                      industry_data['mean_beta'] - industry_data['std_beta'],\n",
    "#                      industry_data['mean_beta'] + industry_data['std_beta'],\n",
    "#                      alpha=0.3)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Beta')\n",
    "plt.title('Mean of Betas by Industry (1996-2023)')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for plotting here\n",
    "import plotly.express as px\n",
    "def plotTimeSeries(df, label):\n",
    "#     try:\n",
    "        fig = px.line(df, x=df.index, y = df['mean_beta'],  title=\"Plot for \" + label)\n",
    "        fig.update_xaxes(nticks=30)\n",
    "        fig.update_layout(\n",
    "            height=600,\n",
    "            width=800\n",
    "        )\n",
    "        fig.show()\n",
    "#     except:\n",
    "#         print(\"Error plotting \" + label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "    Std Deviation of Betas Across industries\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for industry in industries:\n",
    "    industry_data = agg_stats[agg_stats['Industry'] == industry]\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=industry_data['Year'],\n",
    "        y=industry_data['std_beta'],\n",
    "        mode='lines+markers',\n",
    "        name=f'{industry} Std',\n",
    "        line=dict(width=1),\n",
    "        marker=dict(size=3)\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Standard Deviation of Betas by Industry (1996-2023)',\n",
    "    xaxis_title='Year',\n",
    "    yaxis_title='Beta',\n",
    "    legend_title='Industry',\n",
    "    width=1200,\n",
    ")\n",
    "fig.update_xaxes(nticks=28)\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>\n",
    "\n",
    "**Key observations and trends::** \n",
    "\n",
    "- Volatility: Most industries show significant volatility in their beta values over time, with frequent ups and downs rather than steady trends\n",
    "- Range: Beta values generally range between 0.5 and 2.5 for most industries across the period, especially after 2004\n",
    "- Significant drop in Beta seen in Finance and Banking industry in 2008 likely owing to the financial crisis.\n",
    "- High Beta is observed in Construction and Mining sectors. THis likely means that these industries tend to perform better than the market overall as they are a more stable business. \n",
    "- Mining shows huge spike in 2008 and 2020 both in Beta and Volatility of Beta. This means irregular impact in the markets for the mining industry during the financial crisis and COVID.\n",
    "-  In the most recent years during 2017 and 2021, there's increased volatility across many sectors, possibly reflecting the economic uncertainties related to the COVID-19 pandemic. Reason for 2017 is still inconclusive.\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_df['IVOL'] = np.sqrt(beta_df['Residual Var'])\n",
    "beta_df['SVOl'] = np.sqrt((beta_df['Beta'] ** 2) * beta_df['Market Var'])\n",
    "beta_df['TVOL'] = beta_df['SVOl'] + beta_df['IVOL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_vol_stats = beta_df.groupby(['Industry', 'Year'])['TVOL','SVOl','IVOL'].agg(['mean']).reset_index()\n",
    "agg_vol_stats.columns = ['Industry', 'Year', 'TVOL', 'SVOL', 'IVOL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def plotVolatility(agg_stats, industries):\n",
    "    # Loop through each industry to create a separate plot\n",
    "    for industry in industries:\n",
    "        # Filter data for the current industry\n",
    "        industry_data = agg_stats[agg_stats['Industry'] == industry]\n",
    "        \n",
    "        # Ensure 'Year' is numeric and sorted\n",
    "#         industry_data['Year'] = pd.to_numeric(industry_data['Year'], errors='coerce')\n",
    "        industry_data = industry_data.sort_values(by='Year')\n",
    "\n",
    "        # Initialize a figure\n",
    "        fig = go.Figure()\n",
    "\n",
    "        # Plot Total Volatility (TVOL)\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=industry_data['Year'],\n",
    "            y=industry_data['TVOL'],\n",
    "            mode='lines+markers',\n",
    "            name=f'{industry} TVOL',\n",
    "            line=dict(width=1),\n",
    "            marker=dict(size=4)\n",
    "        ))\n",
    "\n",
    "        # Plot Systematic Volatility (SVOL)\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=industry_data['Year'],\n",
    "            y=industry_data['SVOL'],\n",
    "            mode='lines+markers',\n",
    "            name=f'{industry} SVOL',\n",
    "            line=dict(width=1),\n",
    "            marker=dict(size=4)\n",
    "        ))\n",
    "\n",
    "        # Plot Idiosyncratic Volatility (IVOL)\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=industry_data['Year'],\n",
    "            y=industry_data['IVOL'],\n",
    "            mode='lines+markers',\n",
    "            name=f'{industry} IVOL',\n",
    "            line=dict(width=1),\n",
    "            marker=dict(size=4)\n",
    "        ))\n",
    "\n",
    "        # Update layout with title and axis labels\n",
    "        fig.update_layout(\n",
    "            title=f'Volatility Metrics for {industry} (1996-2023)',\n",
    "            xaxis_title='Year',\n",
    "            yaxis_title='Volatility',\n",
    "            legend_title='Volatility Type',\n",
    "            xaxis=dict(tickmode='linear', tick0=1996, dtick=1),  # Ensure yearly ticks on x-axis\n",
    "            width=1000,  # Increase figure width for better readability\n",
    "            height=600\n",
    "        )\n",
    "        \n",
    "        # Display the figure\n",
    "        fig.show()\n",
    "\n",
    "# Example: Assuming you have the 'agg_stats' DataFrame and a list of industries\n",
    "# plotVolatility(agg_stats, industries)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "    Volatility Plots Industry wise Graph for TVOL,IVOL,SVOL\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotVolatility(agg_vol_stats, industries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "\n",
    "### Observation\n",
    "\n",
    "- IVOL major contributor to the TVOL. Most volatility comes from residual volatility of linear regression. This makes sense and sustematic market volatility is less as overall market is more stable than individual stocks. \n",
    "- TVOL, IVOL and SVOL  are dependent and correlated. They all follow the same distribution of trends ie it is not seen that the volatility trends differ from one another (ie. not a single graph with unnatural trends like SVOL increases but TVOL decreases etc.). \n",
    "- Services industry seen to have relativele stable volatility since 2005\n",
    "- Highest Volatility seen in mining\n",
    "- Sharp spikes in TVOL, IVOL and SVOL seen during 2008-2010 period owing to the financial crisis\n",
    "- Sharp spikes in TVOL, IVOL and SVOL seen during 2020-2021 period owing to the COVID pandemic\n",
    "\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas_portfolio = beta_df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_df = final_df.groupby(pd.Grouper(key='date', freq='Y')).agg({'vwretd': 'mean'}).reset_index()\n",
    "yearly_df['date'] = yearly_df['date'].dt.year\n",
    "yearly_df.rename(columns={'date': 'Year'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas_portfolio = betas_portfolio.merge(yearly_df, on='Year', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas_portfolio['returns_excess'] = (betas_portfolio['Beta']) * betas_portfolio['vwretd'] + betas_portfolio['Alpha']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_market_cap_percentage(df):\n",
    "#     yearly_vol = df.groupby(pd.Grouper(key='date', freq='Y')).agg({'vwretd': 'mean'}).reset_index()\n",
    "    df['MarketCap'] = np.abs(df['SHROUT'] * df['PRC'])\n",
    "    yearly_volume = df.groupby([pd.Grouper(key='date', freq='Y'), 'PERMNO'])['MarketCap'].sum().reset_index()\n",
    "    yearly_volume.rename(columns={'date': 'Year'}, inplace=True)\n",
    "    total_volume = yearly_volume.groupby('Year')['MarketCap'].sum().reset_index()\n",
    "    total_volume.columns = ['Year', 'TotalCap']\n",
    "    merged_data = pd.merge(yearly_volume, total_volume, on='Year')\n",
    "    merged_data['MarketCapWeight'] = (merged_data['MarketCap'] / merged_data['TotalCap']) * 100\n",
    "    merged_data['Year'] = merged_data['Year'].dt.year\n",
    "    return merged_data[['PERMNO', 'Year', 'MarketCapWeight']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_cap = compute_market_cap_percentage(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_cap.rename(columns={'PERMNO': 'PERMCO'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_portfolio_valueweighted = pd.merge(betas_portfolio, market_cap, on=['Year', 'PERMCO'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_portfolio_valueweighted['return_weighted'] = beta_portfolio_valueweighted['returns_excess']*beta_portfolio_valueweighted['MarketCapWeight']/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_portfolio_valueweighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createPortfolio(df):\n",
    "    df_sorted = df.sort_values(by='Beta')\n",
    "    df_sorted['quintile'] = pd.qcut(df_sorted['Beta'], 5)\n",
    "    avg_beta = df_sorted.groupby('quintile')['Beta'].mean()\n",
    "    avg_excess_return = df_sorted.groupby('quintile')['returns_excess'].mean()\n",
    "    print(\"Average Beta by Quintile:\\n\", avg_beta)\n",
    "    print (\"\\n\")\n",
    "    \n",
    "    print(\"Equal weighted Portfolio distributions:\")\n",
    "    difference_high_low_beta = avg_excess_return.loc[5] - avg_excess_return.loc[1]\n",
    "    print(\"Average Excess Return by Quintile:\\n\", avg_excess_return)\n",
    "    print(\"Difference in Excess Return (High Beta 5 - Low Beta 1):\", difference_high_low_beta)\n",
    "    print (\"\\n\")\n",
    "    \n",
    "    print(\"Value weighted Portfolio distributions:\")\n",
    "    avg_excess_return_vw = df_sorted.groupby('quintile')['return_weighted'].mean()\n",
    "    difference_high_low_beta_vw = avg_excess_return_vw.loc[5] - avg_excess_return_vw.loc[1]\n",
    "    print(\"Average Excess Return by Quintile:\\n\", avg_excess_return_vw)\n",
    "    print(\"Difference in Excess Return Value Weighted (High Beta 5 - Low Beta 1):\", difference_high_low_beta_vw)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createPortfolioIVol(df):\n",
    "    df_sorted = df.sort_values(by='IVOL')\n",
    "    df_sorted['quintile'] = pd.qcut(df_sorted['IVOL'], 5)\n",
    "    avg_beta1 = df_sorted.groupby('quintile')['Beta'].mean()\n",
    "    avg_excess_return1 = df_sorted.groupby('quintile')['returns_excess'].mean()\n",
    "    print(\"Average Beta by Quintile:\\n\", avg_beta1)\n",
    "    print (\"\\n\")\n",
    "    \n",
    "    print(\"Equal weighted Portfolio distributions:\")\n",
    "    print(\"Average Excess Return by Quintile:\\n\", avg_excess_return1)\n",
    "#     difference_high_low_beta = avg_excess_return[5] - avg_excess_return[1]\n",
    "#     print(\"Difference in Excess Return (High IVOL 5 - Low IVOL 1):\", difference_high_low_beta)\n",
    "    print (\"\\n\")\n",
    "    \n",
    "    print(\"Value weighted Portfolio distributions:\")\n",
    "    avg_excess_return_vw = df_sorted.groupby('quintile')['return_weighted'].mean()\n",
    "#     difference_high_low_beta_vw = avg_excess_return_vw.loc[5] - avg_excess_return_vw.loc[1]\n",
    "    print(\"Average Excess Return by Quintile:\\n\", avg_excess_return_vw)\n",
    "#     print(\"Difference in Excess Return Value Weighted (High IVOL 5 - Low IVOL 1):\", difference_high_low_beta_vw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "    Portfolio Quintile Information (Sorted by Beta)\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "createPortfolio(beta_portfolio_valueweighted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "    Portfolio Quintile Information (Sorted by IVOL)\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "createPortfolioIVol(beta_portfolio_valueweighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h4>\n",
    "References: Some portion of the Code for generating graphs used CHATGPT\n",
    "</h4>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
